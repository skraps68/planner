name: CD - Deploy to Staging

on:
  push:
    branches: [ develop ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: planner-app
  EKS_CLUSTER_NAME: planner-staging-cluster
  K8S_NAMESPACE: planner-app
  DEPLOYMENT_NAME: planner-app

jobs:
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    environment:
      name: staging
      url: https://staging.planner.example.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            --target production \
            --build-arg ENVIRONMENT=staging \
            .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:staging-latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:staging-latest
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT
      
      - name: Configure kubectl
        run: |
          aws eks update-kubeconfig \
            --region ${{ env.AWS_REGION }} \
            --name ${{ env.EKS_CLUSTER_NAME }}
          
          # Verify connection
          kubectl cluster-info
          kubectl get nodes
      
      - name: Run database migrations
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
          TIMESTAMP: ${{ github.sha }}
        run: |
          # Set environment variables for manifest substitution
          export ECR_REPOSITORY=${{ env.ECR_REPOSITORY }}
          export ENVIRONMENT=staging
          export DB_HOST=${{ secrets.STAGING_DB_HOST }}
          export DB_PORT=${{ secrets.STAGING_DB_PORT }}
          export DB_NAME=${{ secrets.STAGING_DB_NAME }}
          export DB_USER=${{ secrets.STAGING_DB_USER }}
          
          # Apply migration job
          envsubst < infrastructure/kubernetes/job-migration.yaml | kubectl apply -f -
          
          # Wait for job to complete
          JOB_NAME="planner-migration-${TIMESTAMP}"
          kubectl wait --for=condition=complete --timeout=600s job/${JOB_NAME} -n ${{ env.K8S_NAMESPACE }} || {
            echo "Migration job failed or timed out"
            kubectl logs -n ${{ env.K8S_NAMESPACE }} job/${JOB_NAME}
            exit 1
          }
          
          echo "Migration completed successfully"
      
      - name: Update Kubernetes secrets
        run: |
          # Update secrets if they don't exist
          kubectl create secret generic planner-secrets \
            --from-literal=db-password="${{ secrets.STAGING_DB_PASSWORD }}" \
            --from-literal=secret-key="${{ secrets.STAGING_SECRET_KEY }}" \
            -n ${{ env.K8S_NAMESPACE }} \
            --dry-run=client -o yaml | kubectl apply -f -
      
      - name: Deploy to EKS
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Set environment variables for manifest substitution
          export ECR_REPOSITORY=${{ env.ECR_REPOSITORY }}
          export ENVIRONMENT=staging
          export DB_HOST=${{ secrets.STAGING_DB_HOST }}
          export DB_PORT=${{ secrets.STAGING_DB_PORT }}
          export DB_NAME=${{ secrets.STAGING_DB_NAME }}
          export DB_USER=${{ secrets.STAGING_DB_USER }}
          export REDIS_HOST=${{ secrets.STAGING_REDIS_HOST }}
          export REDIS_PORT=${{ secrets.STAGING_REDIS_PORT }}
          export APP_POD_ROLE_ARN=${{ secrets.STAGING_APP_POD_ROLE_ARN }}
          
          # Apply Kubernetes manifests
          kubectl apply -f infrastructure/kubernetes/namespace.yaml
          envsubst < infrastructure/kubernetes/serviceaccount.yaml | kubectl apply -f -
          envsubst < infrastructure/kubernetes/deployment.yaml | kubectl apply -f -
          kubectl apply -f infrastructure/kubernetes/service.yaml
          
          # Apply ingress if certificate ARN is provided
          if [ -n "${{ secrets.STAGING_CERTIFICATE_ARN }}" ]; then
            export CERTIFICATE_ARN=${{ secrets.STAGING_CERTIFICATE_ARN }}
            export DOMAIN_NAME=${{ secrets.STAGING_DOMAIN_NAME }}
            envsubst < infrastructure/kubernetes/ingress.yaml | kubectl apply -f -
          fi
          
          # Apply HPA
          kubectl apply -f infrastructure/kubernetes/hpa.yaml
          
          # Wait for rollout to complete
          kubectl rollout status deployment/${{ env.DEPLOYMENT_NAME }} -n ${{ env.K8S_NAMESPACE }} --timeout=600s
      
      - name: Verify deployment
        run: |
          # Check pod status
          kubectl get pods -n ${{ env.K8S_NAMESPACE }}
          
          # Check deployment status
          kubectl get deployment ${{ env.DEPLOYMENT_NAME }} -n ${{ env.K8S_NAMESPACE }}
          
          # Get ingress information
          kubectl get ingress -n ${{ env.K8S_NAMESPACE }}
          
          # Wait for pods to be ready
          kubectl wait --for=condition=ready pod -l app=planner -n ${{ env.K8S_NAMESPACE }} --timeout=300s
          
          # Check health endpoint (if ingress is configured)
          if [ -n "${{ secrets.STAGING_DOMAIN_NAME }}" ]; then
            sleep 30
            curl -f https://${{ secrets.STAGING_DOMAIN_NAME }}/health || echo "Health check failed, but continuing..."
          fi
          
          echo "âœ… Deployment successful! Pods are healthy."
      
      - name: Notify deployment status
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "âœ… Staging deployment successful"
            echo "Image: ${{ steps.build-image.outputs.image }}"
            echo "Cluster: ${{ env.EKS_CLUSTER_NAME }}"
          else
            echo "âŒ Staging deployment failed"
          fi
      
      - name: Rollback on failure
        if: failure()
        run: |
          echo "âš ï¸ Rolling back to previous deployment..."
          
          # Rollback deployment
          kubectl rollout undo deployment/${{ env.DEPLOYMENT_NAME }} -n ${{ env.K8S_NAMESPACE }}
          
          # Wait for rollback to complete
          kubectl rollout status deployment/${{ env.DEPLOYMENT_NAME }} -n ${{ env.K8S_NAMESPACE }} --timeout=300s
          
          echo "ðŸ”„ Automatic rollback completed"
          
          # Show current status
          kubectl get pods -n ${{ env.K8S_NAMESPACE }}
